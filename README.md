# hand-gesture-recognition-sign-Language-using-opencv

During a faithful night at the Gradient ascent Hackathon me and my group wanted to make a sign language to text convrter using hand recognition and ML, but there was lots of trouble already as we found out mediapip which was created by google, was not supported on pythons latest version.This was a very big blow as mediapip makes video and audio programs related to ML very easy. I then created a virtual enviorment on VS code of 3.10 but the depletion of the python versions did not work. We then found a way to get some results but it was of no use as in the final result one library of model which was supposed to help us with imagery of the fingers did not work and our project was incomplete.


I really wanted to do this project so as soon as  I got to the hostel room I immediately got to work trying to improve it, One of the ideas was to use YOLOv function as a replacement to mediapip but that would use way too many lines and would make the whole thing more complicated than neccesary.  doing it alone was way harder than it was at the hackathon with the ideas of different team members I manage to improve it more and more day by day by using more of a simpler method. the Goal is to create a sign language to text convverter which also has facial recognition so it can take facial cues and turn them into emotions, for example the scrunching of the eyebrows can mean angry as just a normal sign language translator does not take the actual emotions to account. I am mainly using just open cv and in it numpy as it is very beneficial for ML especially with things related to ML. I will be updating this repositary every week starting with my first edition of the work in progress software. Mainly made with open cv and numpy
